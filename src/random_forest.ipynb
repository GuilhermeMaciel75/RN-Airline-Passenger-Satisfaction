{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Carregando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/treated_data/train.csv')\n",
    "df_val = pd.read_csv('../data/treated_data/validation.csv')\n",
    "df_test = pd.read_csv('../data/treated_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(['satisfaction'], axis=1)\n",
    "y_train = df_train['satisfaction'].values\n",
    "\n",
    "X_val = df_val.drop(['satisfaction'], axis=1)\n",
    "y_val = df_val['satisfaction'].values\n",
    "\n",
    "X_test = df_test.drop(['satisfaction'], axis=1)\n",
    "y_test = df_test['satisfaction'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajustando variáveis one-hot-encoding para string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_concat = [\n",
    "    'Age',\n",
    "    'Flight Distance',\n",
    "    'Departure Delay in Minutes',\n",
    "    'Arrival Delay in Minutes',\n",
    "    'Gender',\n",
    "    'Customer Type',\n",
    "    'Type of Travel',\n",
    "    'Class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_to_string(df: pd.DataFrame, col: list) -> pd.DataFrame:\n",
    "    for prefix in col:\n",
    "        cols_to_concat = [c for c in df.columns if c.startswith(prefix + '_')]\n",
    "        \n",
    "        if cols_to_concat:\n",
    "            df[prefix] = df[cols_to_concat].astype(str).agg(''.join, axis=1)\n",
    "            \n",
    "            df.drop(cols_to_concat, axis=1, inplace=True)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = one_hot_to_string(df=X_train, col=columns_to_concat)\n",
    "X_val = one_hot_to_string(df=X_val, col=columns_to_concat)\n",
    "X_test = one_hot_to_string(df=X_test, col=columns_to_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Criando o modelo da Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=10,\n",
    "    criterion='gini',\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=df_train.shape[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_pred: np.array, y_test: np.array) -> None:\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Unsatisfied', 'Satisfied'], yticklabels=['Unsatisfied', 'Satisfied'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "print(f'Accuracy no conjunto de Validação: {accuracy_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_pred=y_pred_val, y_test=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_pred: np.array, y_test: np.array) -> None:\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_pred, y_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Accuracy no conjunto de Teste: {accuracy_test:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_pred=y_pred_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Teste K-S\n",
    "\n",
    "1. Estatística K-S (statistic)\n",
    "- Valor da estatística: Este valor é a máxima diferença absoluta entre as funções de distribuição empírica acumulada (ECDFs) das duas amostras comparadas. Quanto menor for a estatística, mais próximas são as distribuições das duas amostras.\n",
    "- Interpretação ideal: Um valor baixo da estatística K-S (próximo de 0) sugere que as distribuições das probabilidades previstas pelo modelo são consistentes entre os subconjuntos de dados (como treino e teste). Isso implica que o modelo é estável e generaliza bem para novos dados, assumindo que não há sobreajuste.\n",
    "2. P-valor\n",
    "- Valor do p-valor: Este valor indica a probabilidade de observar uma diferença tão extrema quanto a estatística K-S, assumindo que as duas amostras são da mesma distribuição.\n",
    "Interpretação ideal:\n",
    "- P-valor alto (por exemplo, > 0.05): Não há evidência estatística suficiente para rejeitar a hipótese de que as distribuições das amostras são iguais. Isto é, parece que o modelo se comporta de forma consistente entre os grupos comparados.\n",
    "- P-valor baixo (por exemplo, < 0.05): Há evidência estatística suficiente para rejeitar a hipótese de que as amostras vêm da mesma distribuição. Isso pode indicar que o modelo está comportando de forma diferente entre os subconjuntos de dados, o que pode ser um sinal de sobreajuste ou de problemas de generalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = model.predict_proba(X_train)  # Probabilidades da classe positiva para o conjunto de treino\n",
    "prob_test = model.predict_proba(X_test) # Probabilidades da classe positiva para o conjunto de teste\n",
    "\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_train = model.predict_proba(X_train)[:, 1]  # Probabilidades da classe positiva para o conjunto de treino\n",
    "prob_test = model.predict_proba(X_test)[:, 1]  # Probabilidades da classe positiva para o conjunto de teste\n",
    "\n",
    "statistic, p_value = ks_2samp(prob_train, prob_test)\n",
    "\n",
    "print(\"K-S statistic:\", statistic)\n",
    "print(\"P-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
